<!DOCTYPE html><html lang="ja"><head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Webcomponent youtube-transcription-player</title>
</head>
<body>
  <h1>Webcomponent youtube-transcription-player</h1>
  <style>
    #el1::part(cue) {
      background: #eee;
      padding: 3px;
      border-radius: 3px;
      margin: 0 4px 4px 0;
    }
    #el1::part(cue):hover {
    background: #ddd;;
    }
  </style>
  <youtube-transcription-player id="el1" videoid="kwnLtaVqDi4" vttsource="https://gist.githubusercontent.com/motemen/5240bb435d3bbc21379aa3de42ddd987/raw/a55d3bdcde104e85e7da4b0e492f4f08cd140c42/kwnLtaVqDi4.vtt"></youtube-transcription-player>

  <style>
    #el2::part(cue) {
      display: block;
    }
    #el2::part(cue):before {
      content: "[" attr(data-cue-time) "] ";
    }
  </style>
  <youtube-transcription-player id="el2" videoid="kwnLtaVqDi4" vttsource="#vtt"></youtube-transcription-player>
  <textarea id="vtt">WEBVTT
Kind: captions
Language: ja

00:00:00.320 --&gt; 00:00:04.700
こんにちは motemen です
今日は作ったものについてご紹介しようと

00:00:04.700 --&gt; 00:00:08.920
思います
まず課題意識としてこんなことありませ

00:00:08.920 --&gt; 00:00:13.920
んかって書いてるんですが
最近はリモートワークで仕事をする人も

00:00:13.920 --&gt; 00:00:20.700
増えてきてリモート会議であったりリモートの
ミーティングのツールを使って人前で話を

00:00:20.700 --&gt; 00:00:26.490
するっていうことをする機会も増えてきた
んじゃないかなと思いますそういうときにです

00:00:26.490 --&gt; 00:00:32.470
ねこういうこともよくあるかなぁと思って
いて参加者がカメラオフにしていたりまた

00:00:32.470 --&gt; 00:00:37.210
モニター越しだと聞いてくれている人
とは視線が合わない目線が合わないという

00:00:37.210 --&gt; 00:00:41.440
こととか
ありますとそうなるとですね話している側

00:00:41.440 --&gt; 00:00:47.050
としてはけっこう身に覚えがあるんじゃないかな
と思うんですが相手の反応がわからない

00:00:47.050 --&gt; 00:00:52.030
はい自分の言ってること伝わっているのかな
とかこれ聞こえているかなみたいなような不安

00:00:52.030 --&gt; 00:00:56.960
になっちゃう喋りにくいってことがあるん
じゃないかなと思うんですね

00:00:56.960 --&gt; 00:01:02.809
そこで作ったのが  vnodroid と
呼んででますがこういうものですまさに今

00:01:02.809 --&gt; 00:01:08.290
画面の左側に出てるんですけど
バーチャルうなずき人間ということでこういう

00:01:08.290 --&gt; 00:01:11.860
名前にしてします
機能としてはまあこっちの話を聞いて

00:01:11.860 --&gt; 00:01:16.540
くれるというだけにつきまして
まず1つは適当なタイミングで頷いて

00:01:16.540 --&gt; 00:01:22.340
くれる適当というか適切なタイミングですね
あとモニターみるといつでも視線がある

00:01:22.340 --&gt; 00:01:28.250
目を見てくれるということですねはい
えっとこれはウェブサイトにアクセスすると

00:01:28.250 --&gt; 00:01:33.470
すぐに使い始めることができます
motemen.github.io/vnodroid/ に

00:01:33.470 --&gt; 00:01:38.170
アクセスでカメラとマイクを許可してあと
はおもむろにしゃべり始めたら ok です

00:01:38.170 --&gt; 00:01:44.030
ここえっといくつか  VRoid Hub と
いうサイトで配布されているものを使って

00:01:44.030 --&gt; 00:01:46.310
まして
いくつか

00:01:46.310 --&gt; 00:01:50.780
デフォルトでサンプルモデルとして提供さ
れている物を使うことができるので

00:01:50.780 --&gt; 00:01:53.800
3種類のキャラクターから選ぶことができます

00:01:53.800 --&gt; 00:02:00.250
技術的には VRM っていう
3Dアバター

00:02:00.250 --&gt; 00:02:04.230
のための規格
ですかねモデルファイルをブラウザ上で

00:02:04.230 --&gt; 00:02:09.750
表示できる three-vrm というのを使って
いて使っておりましたあとですね

00:02:09.750 --&gt; 00:02:13.230
その聞き取りうなずきのタイミングを確定
するために Web Speech API

00:02:13.230 --&gt; 00:02:17.120
というものを利用しています
Web Speech API の中でも

00:02:17.120 --&gt; 00:02:21.110
この聞き取りを行う例えば Chrome
だと webkitSpeechRecognition

00:02:21.110 --&gt; 00:02:26.780
っていう名前なんですがこれを使っ
ていてこれを使うとですねマイク入力をリアル

00:02:26.780 --&gt; 00:02:30.980
タイムに今コンソールだしてますけど文字列として聞き取ることができると

00:02:30.980 --&gt; 00:02:35.390
でリアルタイムに聞き取るんですけど途中で
ですねあの

00:02:35.390 --&gt; 00:02:39.590
聞き取りの内容を確定されるタイ
ミングってのがあるんですね

00:02:39.590 --&gt; 00:02:43.850
まあやっとそうなると意味が確定したん
だろうということで頷きのタイミングにし

00:02:43.850 --&gt; 00:02:47.890
ています
だけどあまりに長すぎると

00:02:47.890 --&gt; 00:02:53.110
なかなか意味が確定しないということで気
聞き取り内容が確定しないということで話の途中

00:02:53.110 --&gt; 00:02:58.950
でも時々今が開いたらうなずきを入れる
みたいな感じで調整してますこの辺は

00:02:58.950 --&gt; 00:03:02.430
自然になるように調整していくのはまあ
これからやっていきたいなということです

00:03:02.430 --&gt; 00:03:06.660
ねはいじゃあ motemen.github.io/vnodroid/ にアクセスしていただければ皆

00:03:06.660 --&gt; 00:03:11.750
さん今日から無料で使い始められますので
どうぞご利用ください
  </textarea>
  

<script type="module" src="./index.js"></script></body></html>